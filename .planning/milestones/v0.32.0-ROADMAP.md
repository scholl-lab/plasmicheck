# Milestone v0.32.0: Performance Optimization

**Status:** SHIPPED 2026-02-14
**Phases:** 4-7
**Total Plans:** 11

## Overview

This roadmap optimized PlasmiCheck pipeline performance by targeting three dominant bottlenecks: report generation (83.6% of time for small datasets), alignment execution (dominant for large datasets), and BAM comparison (11% of time). Delivered 9.5x speedup for small datasets and 1.97x for real-world data through configuration changes and standard library features, with zero breaking changes.

## Phases

### Phase 4: Foundation

**Goal:** Establish regression testing and benchmarking infrastructure to validate that optimizations preserve correctness.
**Depends on:** None (foundation phase)
**Plans:** 2 plans

Plans:
- [x] 04-01-PLAN.md -- Regression test script (TEST-01)
- [x] 04-02-PLAN.md -- Performance benchmark script (TEST-02)

**Requirements delivered:**
- TEST-01: Regression test suite verifying optimization outputs match pre-optimization baseline
- TEST-02: Performance benchmark comparing v0.31.0 vs v0.32.0 on synthetic dataset

**Details:**
- Standalone regression_test.py with --generate and compare modes
- Atomic baseline caching (tempfile + os.replace)
- Benchmark script with per-step timing, warm-up iteration, configurable iterations
- Confirmed report generation was 91.7% bottleneck (5.1s/5.5s)

### Phase 5: Report Optimization

**Goal:** Eliminate report generation bottleneck (83.6% of time) through opt-in PNG export and HTML size reduction.
**Depends on:** Phase 4 (regression tests must pass)
**Plans:** 4 plans

Plans:
- [x] 05-01-PLAN.md -- CLI flags and pipeline wiring (--static-report, --plotly-mode)
- [x] 05-02-PLAN.md -- Single-sample report optimization (generate_report.py + template)
- [x] 05-03-PLAN.md -- Summary report optimization (generate_summary_reports.py + template)
- [x] 05-04-PLAN.md -- Test fixes, CI validation, and regression verification

**Requirements delivered:**
- REPT-01: User can run pipeline without generating static PNG reports
- REPT-02: User can opt into static PNG report generation with --static-report CLI flag
- REPT-03: Interactive HTML reports use shared plotly.min.js file (directory mode)
- REPT-04: User can choose plotly.js inclusion mode via CLI flag (cdn, directory, embedded)
- REPT-05: Kaleido uses start_sync_server() initialization for faster PNG export
- REPT-06: Report-related imports are lazy-loaded inside functions

**Details:**
- Default pipeline: no Kaleido import, no PNG generation (0.108s report step, was 5.1s)
- Directory mode: 19 KB HTML (was 9.6 MB with embedded plotly.js)
- Lazy imports: pandas, plotly, jinja2, numpy, scipy, statsmodels at function level
- 130 tests passing after Phase 5

### Phase 6: Alignment Optimization

**Goal:** Optimize alignment threading with auto-detection across Docker/SLURM/bare-metal environments and configurable sort memory.
**Depends on:** Phase 4 (regression tests must pass)
**Plans:** 2 plans

Plans:
- [x] 06-01-PLAN.md -- Thread detection module, align_reads parameterization, config update
- [x] 06-02-PLAN.md -- CLI --threads flag, pipeline wiring, integration tests

**Requirements delivered:**
- ALGN-01: Plasmid and human alignments run sequentially with full thread allocation
- ALGN-02: Pipeline auto-detects CPU count with cgroup/SLURM awareness
- ALGN-03: User can override thread count with --threads CLI flag
- ALGN-04: All samtools sort commands use -m 2G memory flag

**Details:**
- 5-tier CPU detection: SLURM -> cgroup v2 -> cgroup v1 -> os.cpu_count -> fallback(4)
- Thread allocation: min 2, max 16 total; 80% minimap2, remainder samtools (max 4)
- samtools sort -m 2G: biggest single improvement (human alignment 65.1s -> 13.5s, 4.8x)
- Real dataset (APA19-N, 3M reads): 115.2s -> 58.4s alignment (1.97x speedup)
- 149 tests passing after Phase 6

### Phase 7: Comparison & Cleanup

**Goal:** Optimize BAM comparison with faster name grouping and eliminate redundant index operations.
**Depends on:** Phase 4 (regression tests must pass)
**Plans:** 3 plans

Plans:
- [x] 07-01-PLAN.md -- BAM name grouping benchmarked (collate tested and reverted to sort -n) (COMP-01, COMP-02)
- [x] 07-02-PLAN.md -- Index deduplication, batch resilience, and per-combination timing (ARCH-01, ARCH-02)
- [x] 07-03-PLAN.md -- Matplotlib static plot backend and CLI wiring (ARCH-03)

**Requirements delivered:**
- COMP-01: BAM name grouping benchmarked (collate 28-64x slower, sort -n retained)
- COMP-02: Supplementary alignment ordering validated (sort -n preserves correct ordering)
- ARCH-01: Human reference indexing hoisted out of combination loop
- ARCH-02: PipelinePlan tracks which indexes are already built
- ARCH-03: User can generate static plots via matplotlib backend without Kaleido

**Details:**
- samtools collate benchmarked and reverted: 28-64x slower on filtered BAMs (<100K reads)
- Human index creation hoisted to upfront phase (before combination loop)
- PipelinePlan.built_indexes set for defensive skip checks
- Batch resilience: continue after individual combination failures
- matplotlib plotting subpackage with 4 chart generators matching Plotly output
- --plot-backend CLI flag (plotly/matplotlib) on pipeline, report, summary_reports
- 170 tests passing after Phase 7

---

## Milestone Summary

**Dropped Requirements:**
- TEST-03: Air-gapped Docker test (user decision â€” not blocking)

**Key Decisions:**
- Keep Kaleido v1.2.0 but make PNG export opt-in (not downgrade to 0.2.1)
- Directory mode plotly.js as default for optimal speed/offline balance
- Sequential alignment with full thread allocation (not concurrent)
- samtools sort -n retained (collate benchmarked but 28-64x slower on filtered BAMs)
- matplotlib backend only for static PNG (interactive always Plotly.js)

**Issues Resolved:**
- Report generation bottleneck (91.7% of pipeline time) eliminated
- HTML file bloat (9.6 MB -> 19 KB in directory mode)
- No CPU auto-detection for thread tuning
- Redundant human index creation in batch processing
- Kaleido as hard dependency for static reports

**Issues Deferred:**
- TEST-03: Air-gapped Docker testing (dropped)
- Batch Kaleido export with write_images() (v2 requirement)
- Parallel report generation (v2 requirement)
- lazy_loader library integration (v2 requirement)

**Technical Debt Incurred:**
- Phase 7 VERIFICATION.md references collate as active (stale after revert)
- Phase 5 runtime benchmarks verified structurally, not by actual benchmark run

---

## Performance Results

| Metric | v0.31.0 | v0.32.0 | Improvement |
|--------|---------|---------|-------------|
| Synthetic dataset (200 reads) | 5.5s | 0.577s | 9.5x faster |
| Real dataset alignment (3M reads) | 115.2s | 58.4s | 1.97x faster |
| Report step (default, no static) | ~5.1s | 0.108s | ~100x faster |
| Interactive HTML size | 9.6 MB | ~19 KB | 99.8% reduction |
| CLI startup (lazy imports) | - | -231ms | Measurable reduction |
| Unit tests | 125 | 170 | +45 new tests |

---

_For current project status, see .planning/ROADMAP.md_
_Archived: 2026-02-14 as part of v0.32.0 milestone completion_
