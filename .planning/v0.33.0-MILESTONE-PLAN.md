# PlasmiCheck v0.33.0 Milestone Plan: Scientific & Reporting Enhancements

**Date:** 2026-02-14
**Base version:** v0.32.0 (branch `main`)
**Milestone focus:** Improve scientific accuracy and reporting completeness

---

## Executive Summary

This milestone addresses the 4 highest-impact open issues from the Tier 5 backlog. Together, they transform PlasmiCheck from a tool that produces a single contamination ratio into one that provides **multi-dimensional evidence** for contamination calls: insert-region-aware filtering, resistance gene coverage, comprehensive depth/breadth metrics, and full metric integration in summary reports.

**Why these 4 issues together:** They form a natural dependency chain and complement each other scientifically:

1. **#82** (filter ambiguous reads) fixes a **scientific accuracy bug** -- the most critical issue
2. **#64** (resistance gene coverage) adds an **orthogonal contamination signal** -- strongest evidence
3. **#65** (coverage metrics) provides **quantitative depth/breadth/uniformity data** -- standard QC
4. **#58** (integrate metrics in summary) **surfaces all existing + new metrics** in reports -- visibility

---

## Issue Deep Dives

### Issue #82: Filter Ambiguous Reads (HIGHEST PRIORITY)

**Problem:** When a sample is heavily contaminated with Plasmid A, reads from shared backbone regions (pUC origin, CMV promoter, BGH polyA, etc.) align to *all* plasmids that share those backbone elements. These "backbone-only" reads are compared against human score 0 (no human reference for backbone regions) and are always assigned to "Plasmid" -- inflating contamination scores for unrelated plasmids and producing **false positive contamination calls**.

**Root cause in code:** In `compare_alignments.py`, `_streaming_compare()` handles plasmid-only reads (lines 236-244) by calling `_assign(plasmid_score, 0)`. Any positive score results in a "Plasmid" assignment. There is no distinction between reads mapping to the insert region (biologically informative) versus backbone (shared/ambiguous).

**Current scoring logic:**
```
score = MAPQ - clipping*1 - mismatches*1 + mate_bonus(10)
ratio = plasmid_count / human_count → verdict
```
No minimum score threshold, no score margin, no region awareness.

**Recommended approach: Insert-Region Aware Filtering + Score Margin**

Two complementary mechanisms:

1. **Insert-region awareness (primary fix):** Use the already-computed `INSERT_REGION` from `cDNA_positions.txt` to classify plasmid-only reads. Reads mapping outside the insert region are tagged `Backbone_Only` and excluded from the ratio calculation. This directly addresses the root cause.

2. **Score margin (secondary):** Require `|plasmid_score - human_score| >= margin` (configurable, default 0 for backward compatibility) before confident assignment. Reads below the margin are tagged `Ambiguous`.

**New read categories:**
| Category | Definition | In ratio? |
|----------|-----------|-----------|
| Plasmid | Overlaps insert, clear winner | Yes |
| Human | Clear winner | Yes |
| Tied | Exact score match | No (existing) |
| Backbone_Only | Plasmid-only, outside insert | No (new) |
| Ambiguous | Score difference < margin | No (new) |

**Files to modify:**
| File | Change |
|------|--------|
| `plasmicheck/scripts/compare_alignments.py` | Add `insert_region` param to `_streaming_compare()`, classify backbone-only reads, optional score margin in `_assign()` |
| `plasmicheck/scripts/run_pipeline.py` | Pass `insert_region` (from `cDNA_positions.txt`) to `compare_alignments()` |
| `plasmicheck/config.json` | Add `filter_backbone_only` (default: true), `score_margin` (default: 0) |
| `plasmicheck/scripts/generate_report.py` | Display new categories in plots |
| `plasmicheck/templates/report_template.html` | Render Backbone_Only and Ambiguous counts |
| `tests/test_compare_alignments.py` | Tests for backbone classification, score margin, backward compat |
| `tests/conftest.py` | New fixtures for backbone/ambiguous reads |

**Estimated complexity:** Medium (~100-150 LoC changed)

**Scientific justification:** The insert region is what differentiates plasmids; the backbone is shared. This mirrors best practices from FastQ Screen (read uniqueness categorization), ConFindr (analysis restricted to discriminative regions), and ContScout (explicit shared-sequence handling). See: [FastQ Screen](https://pmc.ncbi.nlm.nih.gov/articles/PMC6124377/), [ConFindr](https://pmc.ncbi.nlm.nih.gov/articles/PMC6546082/), [Contamination detection review](https://link.springer.com/article/10.1186/s13059-022-02619-9).

---

### Issue #64: Resistance Gene Coverage

**Problem:** PlasmiCheck treats the backbone as a single undifferentiated region. It has zero awareness of functional elements (resistance genes, origins, promoters). Reads covering antibiotic resistance genes (AmpR, KanR, HygR, etc.) are **unambiguously non-human** -- these prokaryotic genes have no human homolog. They provide the strongest possible independent contamination signal.

**Current behavior:** `calculate_coverage_outside_insert()` averages coverage across the entire backbone (~3-5 kb), diluting the signal from resistance genes (~0.6-1.0 kb each).

**Recommended approach: Annotation-first with built-in sequence fallback**

1. **Primary: Parse GenBank annotations.** Extract CDS/gene features matching known resistance gene label patterns from the user's GenBank file using Biopython's `SeqIO`.

2. **Fallback: Built-in reference database.** A small FASTA (~10 KB, ~10-15 canonical resistance gene sequences) shipped with the package, aligned via minimap2 when annotations are sparse.

**Resistance gene catalog:**

| Gene | Product | Antibiotic | Size (bp) | Vectors |
|------|---------|-----------|-----------|---------|
| bla (TEM-1) | Beta-lactamase | Ampicillin | ~861 | pUC, pBR322, pcDNA |
| aph(3')/nptII | Aminoglycoside phosphotransferase | Kanamycin | ~792 | pET-28, pEGFP |
| cat | Chloramphenicol acetyltransferase | Chloramphenicol | ~660 | pACYC184 |
| hph | Hygromycin phosphotransferase | Hygromycin | ~1026 | pcDNA5/FRT |
| pac | Puromycin N-acetyltransferase | Puromycin | ~600 | pLVX-Puro |
| neo | Neomycin phosphotransferase II | G418 | ~795 | pcDNA3.1 |
| tet | Tetracycline efflux pump | Tetracycline | ~1191 | pBR322 |
| zeo | Zeocin binding protein | Zeocin | ~375 | pcDNA3.1/Zeo |
| bsr | Blasticidin S deaminase | Blasticidin | ~396 | pLenti6 |
| aadA | Aminoglycoside adenylyltransferase | Spectinomycin | ~792 | Gateway |

**Label patterns for annotation matching:**
```python
RESISTANCE_GENE_PATTERNS = {
    "AmpR": ["AmpR", "Amp", "bla", "beta-lactamase", "ampicillin resistance"],
    "KanR": ["KanR", "Kan", "nptII", "aph(3')", "kanamycin resistance", "neo"],
    "HygR": ["HygR", "hph", "hygromycin"],
    "PuroR": ["PuroR", "pac", "puromycin"],
    # ... etc
}
```

**Evidence from repository plasmids:** Examined 6 GenBank files in `reference/plasmid/`. All contain resistance genes (AmpR in 5/6, HygR in 2/6). Annotation quality varies: some use `/label="AmpR"`, others `/label="Amp"`, one only annotates the promoter (`Amp prom`). This variation motivates the fallback approach.

**Per-gene coverage metrics:**
- Mean coverage depth
- Breadth of coverage (fraction of gene with >= 1 read)
- Number of spanning reads
- Normalized coverage (relative to insert for comparison)

**New files:**
| File | Purpose |
|------|---------|
| `plasmicheck/scripts/resistance_genes.py` | Gene detection (annotation + fallback) and coverage calculation |
| `plasmicheck/data/resistance_gene_sequences.fasta` | Built-in reference sequences (optional Phase 2) |
| `tests/test_resistance_genes.py` | Unit tests |

**Files to modify:**
| File | Change |
|------|--------|
| `plasmicheck/scripts/compare_alignments.py` | Call resistance gene coverage after existing metrics |
| `plasmicheck/scripts/run_pipeline.py` | Pass GenBank path to comparison step |
| `plasmicheck/scripts/generate_report.py` | Add resistance gene section to single-sample report |
| `plasmicheck/scripts/generate_summary_reports.py` | Parse and aggregate resistance gene metrics |
| `plasmicheck/templates/report_template.html` | Resistance gene results table |
| `plasmicheck/templates/summary_template.html` | Resistance gene columns in summary |
| `plasmicheck/config.json` | Detection settings, label patterns |
| `tests/data/synthetic/generate_test_data.py` | Add resistance gene CDS to synthetic plasmid.gb |

**Estimated complexity:** Medium (~200-250 LoC new)

**Sources:** [Addgene: Resistance Genes Guide](https://blog.addgene.org/plasmids-101-everything-you-need-to-know-about-antibiotic-resistance-genes), [CARD Database](https://card.mcmaster.ca/), [AMRFinderPlus](https://www.ncbi.nlm.nih.gov/pathogens/antimicrobial-resistance/AMRFinder/)

---

### Issue #65: Add Coverage Metrics to Summary Report

**Problem:** PlasmiCheck currently computes only a crude `CoverageOutsideINSERT` metric (total aligned bases / region length). It lacks standard sequencing QC metrics: per-base depth, breadth of coverage, coverage uniformity. Without these, users cannot assess whether a contamination ratio is backed by meaningful sequencing depth or is an artifact of low coverage.

**What to compute:** Per-region (insert vs backbone) metrics using `pysam.count_coverage()`:

| Metric | Region | Type | Why |
|--------|--------|------|-----|
| `mean_depth_insert` | Insert | Depth | Baseline: expected from both contaminated and clean |
| `mean_depth_backbone` | Backbone | Depth | Key indicator: only from plasmid contamination |
| `median_depth_backbone` | Backbone | Depth | Robust to outliers |
| `breadth_insert` | Insert | Breadth (%) | Should be ~100% if well-mapped |
| `breadth_backbone` | Backbone | Breadth (%) | Strong contamination signal |
| `breadth_backbone_5x` | Backbone | Breadth at 5x (%) | Reliable coverage threshold |
| `coverage_cv_backbone` | Backbone | Uniformity (CV) | Low CV = genuine contamination (uniform reads) |

**Implementation approach:**
```python
def calculate_coverage_metrics(plasmid_bam, insert_region):
    a, c, g, t = bamfile.count_coverage(ref_name, start=0, stop=ref_length)
    per_base_depth = np.array(a) + np.array(c) + np.array(g) + np.array(t)
    # Split into insert vs backbone, compute metrics per region
```

Uses `pysam.count_coverage()` (C-implemented via htslib) -- fast and memory-efficient on small plasmid references (5-15 kb). No external tools needed.

**New metrics written to `summary.tsv`** as additional `Category\tValue` rows (additive, backward compatible).

**Visualization in summary report:**
- Coverage depth heatmap (Sample x Plasmid, analogous to existing ratio heatmap)
- Backbone breadth heatmap (0-100%, red-yellow-green scale)
- Coverage boxplot by plasmid (log scale depth distribution)

**Files to modify:**
| File | Change |
|------|--------|
| `plasmicheck/scripts/compare_alignments.py` | New `calculate_coverage_metrics()` function, call after existing metrics |
| `plasmicheck/scripts/generate_summary_reports.py` | Parse new categories, create heatmaps/boxplots/tables |
| `plasmicheck/templates/summary_template.html` | Coverage section with plots and tables |
| `plasmicheck/scripts/plotting/matplotlib_backend.py` | Matplotlib fallback for coverage plots |
| `plasmicheck/config.json` | Plot config for coverage heatmaps |
| `tests/test_compare_alignments.py` | Tests for coverage metrics |
| `tests/conftest.py` | Update `sample_summary_df` fixture with new categories |

**Estimated complexity:** Low-Medium (~150-200 LoC new)

**Sources:** [Sequencing Coverage Explained](https://www.cd-genomics.com/resource-sequencing-depth-and-coverage.html), [Breadth of Coverage](https://www.reneshbedre.com/blog/sequencing-coverage.html), [Coverage Uniformity Metrics](https://pmc.ncbi.nlm.nih.gov/articles/PMC5429826/), [Illumina Coverage Guide](https://www.illumina.com/science/technology/next-generation-sequencing/plan-experiments/coverage.html)

---

### Issue #58: Integrate Existing Metrics in Summary Report (QUICK WIN)

**Problem:** `CoverageOutsideINSERT` and `MismatchesNearINSERT` are already computed in `compare_alignments.py` and written to every `summary.tsv`, but are **completely ignored** by the summary report generator. They appear in single-sample reports (as raw table rows) but not in multi-sample summary reports.

**Current data flow:**
1. `compare_alignments.py` computes both metrics and writes to `summary.tsv` (lines 323-324)
2. `generate_summary_reports.py` reads all `summary.tsv` files into a concatenated DataFrame
3. The DataFrame **contains** CoverageOutsideINSERT and MismatchesNearINSERT rows
4. But `main()` only filters for `Ratio`, `Plasmid/Human/Tied`, and `Verdict` -- the two metrics are silently dropped

**Data format:**
- `CoverageOutsideINSERT`: numeric string (e.g., `"0.1234"`) -- `pd.to_numeric()` suffices
- `MismatchesNearINSERT`: Python dict repr string (e.g., `"{'with_mismatches_or_clipping': 5, 'without_mismatches_or_clipping': 10}"`) -- needs `ast.literal_eval()` + column extraction

**What to add:**

| New Element | Type | Details |
|-------------|------|---------|
| Coverage Outside INSERT Heatmap | Plot | Sample x Plasmid, sequential colorscale |
| Coverage Outside INSERT Boxplot | Plot | Distribution by plasmid |
| Coverage Outside INSERT Table | Table | Sample, Plasmid, Value |
| Mismatches Near INSERT Chart | Plot | Stacked/grouped bar or ratio heatmap |
| Mismatches Near INSERT Table | Table | Sample, Plasmid, With, Without |

**Files to modify:**
| File | Change |
|------|--------|
| `plasmicheck/scripts/generate_summary_reports.py` | Parse metrics, create plots/tables, pass to template |
| `plasmicheck/templates/summary_template.html` | New sections for both metrics |
| `plasmicheck/scripts/plotting/matplotlib_backend.py` | Matplotlib fallback for new plots |
| `plasmicheck/config.json` | Plot config entries |

**Estimated complexity:** Low (~100-150 LoC)

**Note:** This issue is a natural prerequisite/subset of #65. The new coverage metrics from #65 will follow the same integration pattern established by #58.

---

## Phased Implementation Plan

### Phase 1: Ambiguous Read Filtering (#82)

**Goal:** Eliminate false positive contamination calls caused by backbone-shared reads.

**Why first:** This is a scientific accuracy fix. All downstream metrics and reports build on the corrected read assignment logic. Must be done before adding new metrics that depend on correct assignments.

**Tasks:**
1. Add `insert_region` parameter to `_streaming_compare()` and `compare_alignments()`
2. Implement backbone-only read classification using positional overlap check
3. Add optional `score_margin` parameter to `_assign()`
4. Update ratio calculation to exclude Backbone_Only and Ambiguous reads
5. Add `filter_backbone_only` and `score_margin` config entries
6. Pass `insert_region` from `run_pipeline.py` to `compare_alignments()`
7. Update single-sample report to display new categories
8. Update summary template with new categories
9. Comprehensive unit tests (backbone classification, margin behavior, backward compat)
10. Update synthetic test data if needed

**Success criteria:**
- A sample contaminated with Plasmid A no longer shows elevated scores for unrelated Plasmid B (when only shared backbone reads are present)
- Existing test suite passes with default config (backward compatible)
- New categories (Backbone_Only, Ambiguous) tracked and displayed in reports
- `filter_backbone_only=false` restores exact pre-v0.33.0 behavior

**Estimated LoC:** ~150 new/modified

---

### Phase 2: Coverage Metrics Computation (#65)

**Goal:** Add comprehensive per-region coverage depth, breadth, and uniformity metrics.

**Why second:** These metrics quantify the confidence behind contamination calls. The insert-region concept is already established in Phase 1.

**Tasks:**
1. Implement `calculate_coverage_metrics()` in `compare_alignments.py` using `pysam.count_coverage()`
2. Compute per-region metrics: mean/median depth, breadth, breadth@5x, CV
3. Write new metrics as additional rows in `summary.tsv`
4. Retain existing `CoverageOutsideINSERT` for backward compatibility
5. Unit tests for coverage calculation with mock pysam data
6. Update `regression_test.py` to handle new categories

**Success criteria:**
- New coverage metrics present in all `summary.tsv` output files
- Metrics calculated per-region (insert vs backbone) using actual per-base depth
- Computation fast (<100ms on typical plasmid BAMs)
- Backward compatible (new rows appended, existing rows unchanged)

**Estimated LoC:** ~100-150 new

---

### Phase 3: Resistance Gene Coverage (#64)

**Goal:** Detect and report per-gene coverage for known resistance markers.

**Why third:** Builds on the coverage infrastructure from Phase 2. Adds the most biologically meaningful contamination signal.

**Tasks:**
1. Create `plasmicheck/scripts/resistance_genes.py` module
2. Implement `RESISTANCE_GENE_PATTERNS` dictionary for annotation matching
3. Implement `extract_resistance_genes_from_genbank()` using Biopython feature parsing
4. Implement `calculate_resistance_gene_coverage()` using pysam
5. Define `ResistanceGene` and `ResistanceGeneCoverage` dataclasses
6. Wire into `compare_alignments()` -- pass GenBank path from `run_pipeline.py`
7. Write per-gene metrics to `summary.tsv` (e.g., `ResistanceGeneCoverage_AmpR`)
8. Add resistance gene CDS feature to synthetic `plasmid.gb` test data
9. Comprehensive unit tests in `tests/test_resistance_genes.py`
10. (Optional Phase 3b): Built-in reference FASTA for unannotated plasmids

**Success criteria:**
- Resistance genes detected from GenBank annotations with >90% recall across real plasmid files in the repository
- Per-gene coverage (depth + breadth) computed and written to summary.tsv
- Works with existing plasmid files (verified against 6 GenBank files in `reference/plasmid/`)
- Synthetic test data includes a resistance gene for integration testing

**Estimated LoC:** ~200-250 new

---

### Phase 4: Report Integration (#58 + #65 + #64 visualization)

**Goal:** Surface all metrics (existing + new) in summary reports with plots and tables.

**Why last:** All data sources must be in place before building the visualization layer. This phase adds no new computation -- it's purely rendering.

**Tasks:**
1. Parse `CoverageOutsideINSERT` and `MismatchesNearINSERT` from aggregated DataFrame (#58)
2. Parse new coverage metrics from Phase 2 (#65)
3. Parse resistance gene metrics from Phase 3 (#64)
4. Create coverage depth heatmap (Sample x Plasmid, backbone mean depth)
5. Create coverage breadth heatmap (backbone breadth %)
6. Create coverage boxplot (backbone depth distribution by plasmid)
7. Create mismatches near insert chart (stacked bar or ratio heatmap)
8. Create resistance gene coverage table/heatmap
9. Add all plots/tables to `summary_template.html` with Jinja2 conditionals for backward compat
10. Add matplotlib fallback functions for all new plots
11. Update `save_tables_as_tsv_and_excel()` with new DataFrames
12. Update `config.json` with plot configuration entries

**Success criteria:**
- All metrics visible in both interactive (Plotly) and static (matplotlib) summary reports
- New report sections degrade gracefully when metrics are absent (old data)
- TSV and Excel exports include new metric tables
- Plots follow existing visual style (color scales, layout, dimensions)

**Estimated LoC:** ~250-300 new

---

## Dependency Graph

```
Phase 1: #82 (ambiguous filtering)
    │
    ├──► Phase 2: #65 (coverage metrics)
    │        │
    │        └──► Phase 3: #64 (resistance genes)
    │                 │
    └─────────────────┘
                      │
                      ▼
              Phase 4: #58 + visualization
```

Phase 1 must come first (corrects read assignments that all other metrics depend on).
Phases 2 and 3 could be parallelized but share coverage infrastructure.
Phase 4 is the pure visualization/integration layer.

---

## Risk Assessment

| Risk | Impact | Mitigation |
|------|--------|------------|
| Insert-region filtering changes contamination verdicts | Breaking change for existing analyses | Ship with `filter_backbone_only=true` default but document behavioral change; `false` restores old behavior |
| GenBank annotation quality varies | Some resistance genes undetected | Built-in sequence fallback (Phase 3b), extensive label pattern matching |
| `pysam.count_coverage()` API differences across versions | Coverage computation may fail | Pin pysam minimum version, add fallback to manual pileup iteration |
| New metrics increase summary.tsv size | Breaks downstream parsers | Additive format (new rows), existing parsers unaffected |
| numpy dependency for coverage computation | New direct dependency | Already a transitive dependency (pandas, scipy); just formalize in pyproject.toml |

---

## Testing Strategy

| Test Type | Scope | Count (est.) |
|-----------|-------|-------------|
| Unit tests: backbone classification | Phase 1 | 8-10 new |
| Unit tests: score margin | Phase 1 | 4-6 new |
| Unit tests: coverage metrics | Phase 2 | 6-8 new |
| Unit tests: resistance gene detection | Phase 3 | 8-10 new |
| Unit tests: resistance gene coverage | Phase 3 | 4-6 new |
| Unit tests: summary report integration | Phase 4 | 6-8 new |
| Integration tests: full pipeline | All phases | 2-4 new |
| Regression test: backward compat | Phase 1 | Update existing |
| **Total new tests** | | **~40-50** |

**Target:** 170 existing + ~45 new = **~215 tests**

---

## Version Plan

| Phase | Version | Tag | Issues Closed |
|-------|---------|-----|---------------|
| Phase 1 | 0.33.0-alpha | - | - |
| Phase 2 | 0.33.0-beta | - | #65 |
| Phase 3 | 0.33.0-rc | - | #64 |
| Phase 4 | 0.33.0 | v0.33.0 | #82, #58 |

All 4 issues closed at final release since the full feature set (filtering + metrics + visualization) delivers the complete user-facing value.

---

## Files Inventory

### New files
| File | Phase | Purpose |
|------|-------|---------|
| `plasmicheck/scripts/resistance_genes.py` | 3 | Gene detection + coverage |
| `plasmicheck/data/resistance_gene_sequences.fasta` | 3b | Built-in reference (optional) |
| `tests/test_resistance_genes.py` | 3 | Unit tests |

### Modified files (all phases)
| File | Phases | Changes |
|------|--------|---------|
| `plasmicheck/scripts/compare_alignments.py` | 1, 2 | Insert-aware filtering, coverage metrics |
| `plasmicheck/scripts/run_pipeline.py` | 1, 3 | Pass insert_region and GenBank path |
| `plasmicheck/scripts/generate_report.py` | 1, 4 | New categories, coverage sections |
| `plasmicheck/scripts/generate_summary_reports.py` | 4 | Parse + plot all new metrics |
| `plasmicheck/scripts/plotting/matplotlib_backend.py` | 4 | Matplotlib fallback for new plots |
| `plasmicheck/templates/report_template.html` | 1, 3, 4 | New report sections |
| `plasmicheck/templates/summary_template.html` | 4 | Coverage + resistance gene sections |
| `plasmicheck/config.json` | 1, 2, 3, 4 | New settings and plot config |
| `tests/test_compare_alignments.py` | 1, 2 | Backbone + coverage tests |
| `tests/conftest.py` | 1, 2, 4 | Updated fixtures |
| `tests/data/synthetic/generate_test_data.py` | 3 | Add resistance gene to synthetic data |
| `scripts/regression_test.py` | 2, 3 | Handle new summary.tsv categories |
| `plasmicheck/version.py` | 4 | Bump to 0.33.0 |

---

## Success Criteria (Milestone-Level)

1. A heavily contaminated sample with Plasmid A no longer triggers false positive contamination calls for unrelated plasmids sharing only backbone sequence
2. Resistance genes are detected from GenBank annotations and their coverage is reported per-gene
3. Comprehensive coverage metrics (depth, breadth, uniformity) are computed per-region (insert vs backbone) for every sample-plasmid pair
4. All metrics -- existing (`CoverageOutsideINSERT`, `MismatchesNearINSERT`) and new -- are visible in summary reports with appropriate visualizations
5. All tests pass (~215 total), including backward compatibility with `filter_backbone_only=false`
6. No new external tool dependencies (uses existing pysam, Biopython, minimap2)

---

## References

- [FastQ Screen: Multi-genome mapping and quality control](https://pmc.ncbi.nlm.nih.gov/articles/PMC6124377/)
- [ConFindr: Rapid detection of intra/cross-species contamination](https://pmc.ncbi.nlm.nih.gov/articles/PMC6546082/)
- [Contamination detection in genomic data: more is not enough](https://link.springer.com/article/10.1186/s13059-022-02619-9)
- [ContScout: Sensitive detection and removal of contamination](https://pmc.ncbi.nlm.nih.gov/articles/PMC10831095/)
- [Addgene: Plasmids 101 - Antibiotic Resistance Genes](https://blog.addgene.org/plasmids-101-everything-you-need-to-know-about-antibiotic-resistance-genes)
- [CARD - Comprehensive Antibiotic Resistance Database](https://card.mcmaster.ca/)
- [Sequencing Depth and Coverage Explained](https://www.cd-genomics.com/resource-sequencing-depth-and-coverage.html)
- [Coverage Uniformity Metrics (PMC)](https://pmc.ncbi.nlm.nih.gov/articles/PMC5429826/)
- [Illumina: Sequencing Coverage Guide](https://www.illumina.com/science/technology/next-generation-sequencing/plan-experiments/coverage.html)
- [MAPQ values discussion](https://sequencing.qcfail.com/articles/mapq-values-are-really-useful-but-their-implementation-is-a-mess/)
