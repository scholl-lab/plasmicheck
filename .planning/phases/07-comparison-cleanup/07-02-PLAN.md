---
phase: 07-comparison-cleanup
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - plasmicheck/scripts/run_pipeline.py
  - tests/test_run_pipeline.py
autonomous: true

must_haves:
  truths:
    - "Human reference indexing is performed once upfront before any combination is processed"
    - "PipelinePlan tracks which indexes have been built, skipping redundant index creation"
    - "Redundant human index operations are skipped with INFO-level log message"
    - "Pipeline continues processing remaining combinations when one fails"
    - "Failed combinations are logged with error details at ERROR level"
    - "Per-combination timing is logged at INFO level"
    - "Summary report is generated for successful combinations only"
  artifacts:
    - path: "plasmicheck/scripts/run_pipeline.py"
      provides: "PipelinePlan.built_indexes field, upfront index phase, batch resilience"
      contains: "built_indexes"
    - path: "plasmicheck/scripts/run_pipeline.py"
      provides: "CombinationResult dataclass for tracking success/failure/timing"
      contains: "CombinationResult"
    - path: "tests/test_run_pipeline.py"
      provides: "Tests for index dedup, batch resilience, and timing"
      contains: "test_index_dedup"
  key_links:
    - from: "plasmicheck/scripts/run_pipeline.py"
      to: "PipelinePlan.built_indexes"
      via: "set tracking which indexes are built"
      pattern: "built_indexes"
    - from: "plasmicheck/scripts/run_pipeline.py"
      to: "create_indexes"
      via: "called once per unique human reference in upfront phase"
      pattern: "Skipping index for.*already built"
    - from: "plasmicheck/scripts/run_pipeline.py"
      to: "CombinationResult"
      via: "tracks success, duration, error for each combination"
      pattern: "CombinationResult"
---

<objective>
Hoist human reference indexing out of the combination loop into an upfront planning phase, add index tracking to PipelinePlan, and implement batch resilience with per-combination timing.

Purpose: In batch runs with 10+ sample-plasmid combinations sharing the same human reference, the current code calls `create_indexes(human_fasta)` for every combination. While filelock prevents redundant work, it still incurs lock acquisition overhead and log noise. Upfront planning eliminates this. Batch resilience prevents one failed combination from halting the entire batch.

Output: Updated run_pipeline.py with upfront indexing phase, PipelinePlan.built_indexes tracking, continue-on-failure processing, per-combination timing, and unit tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-comparison-cleanup/07-CONTEXT.md
@.planning/phases/07-comparison-cleanup/07-RESEARCH.md
@plasmicheck/scripts/run_pipeline.py
@plasmicheck/scripts/create_indexes.py
@tests/test_run_pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add index tracking to PipelinePlan and upfront indexing phase</name>
  <files>plasmicheck/scripts/run_pipeline.py</files>
  <action>
  Modify `plasmicheck/scripts/run_pipeline.py`:

  1. **Add `built_indexes: set[str]` field to PipelinePlan dataclass** with `field(default_factory=set)`. This tracks file paths of indexes that have been built or confirmed to exist.

  2. **Add `CombinationResult` dataclass** (after PipelinePlan):
     ```python
     @dataclass
     class CombinationResult:
         combo_label: str
         success: bool
         duration: float
         error: Exception | None = None
     ```

  3. **Add `import time` to imports.**

  4. **Modify `run_pipeline()` — add upfront human indexing phase** between quality control and the combination loop:
     - After the quality control section and before `with _progress_context(...)`:
     - Compute the human index path: `human_index_path = os.path.join(os.path.dirname(human_fasta), os.path.splitext(os.path.basename(human_fasta))[0] + ".mmi")`
     - Check if it exists or needs building: `if not os.path.exists(human_index_path) or plan.overwrite:`
     - Call `create_indexes(human_fasta, overwrite)` once
     - Add to tracking: `plan.built_indexes.add(human_index_path)`
     - Log: `logging.info(f"Built human reference index: {human_index_path}")`
     - Else: `plan.built_indexes.add(human_index_path)` and `logging.info(f"Skipping index for {human_fasta} (already built)")`

  5. **Modify the combination loop — skip redundant human indexing**:
     - In Step 2 (index creation), replace the current `create_indexes(human_fasta, overwrite)` call:
     - Check: `if human_index not in plan.built_indexes:` — only call `create_indexes(human_fasta, overwrite)` if not already tracked (defensive, should not happen after upfront phase)
     - Keep `create_indexes(plasmid_fasta, overwrite)` as-is (plasmid indexes are cheap, no dedup per CONTEXT decision)

  6. **Wrap each combination in try-except for batch resilience**:
     - Add a `results: list[CombinationResult] = []` before the progress context
     - Inside the `for seq_input in plan.sequencing_inputs:` loop, wrap the entire combination processing (Steps 1-9) in `try: ... except Exception as e:`
     - In the try block: record `start_time = time.time()` before processing, `duration = time.time() - start_time` after
     - On success: `results.append(CombinationResult(combo_label=f"{os.path.basename(plasmid_file)} x {os.path.basename(sequencing_file)}", success=True, duration=duration))`
     - Log: `logging.info(f"{combo_label}: {duration:.1f}s")`
     - On exception: `results.append(CombinationResult(combo_label=..., success=False, duration=time.time()-start_time, error=e))`
     - Log: `logging.error(f"{combo_label} FAILED after {duration:.1f}s: {e}")`
     - Continue to next combination (do not re-raise)

  7. **After the combination loop, log batch summary**:
     - Count successful and failed
     - `logging.info(f"Pipeline complete: {len(successful)} succeeded, {len(failed)} failed")`
     - If any failed: `logging.warning(f"Failed combinations:")` and list each
     - If ALL failed: raise RuntimeError with summary of failures

  8. **Update `build_plan()` to include `built_indexes` initialization** — already done via dataclass default.

  9. **Update `print_plan()` dry-run output** to show that human indexing is hoisted:
     - Add a line after "Execution Plan": `"  Human index: {human_index_path} (built once, shared across all combinations)"`
  </action>
  <verify>
  - `make lint` passes
  - `make typecheck` passes
  - `python -c "from plasmicheck.scripts.run_pipeline import PipelinePlan, CombinationResult; p = PipelinePlan('h', [], [], 'o', False); print(type(p.built_indexes))"` prints `<class 'set'>`
  </verify>
  <done>
  - PipelinePlan has `built_indexes: set[str]` field
  - CombinationResult dataclass exists with combo_label, success, duration, error fields
  - Human reference indexing called once before combination loop
  - Combination loop skips redundant human index creation
  - Each combination wrapped in try-except, failures logged, processing continues
  - Per-combination timing logged at INFO level
  - Batch summary logged after all combinations
  </done>
</task>

<task type="auto">
  <name>Task 2: Add unit tests for index deduplication and batch resilience</name>
  <files>tests/test_run_pipeline.py</files>
  <action>
  Add tests to `tests/test_run_pipeline.py` covering index deduplication and batch resilience:

  1. **`test_pipeline_plan_has_built_indexes_field`**: Create a PipelinePlan instance and verify `built_indexes` is a set and starts empty.

  2. **`test_combination_result_dataclass`**: Create CombinationResult instances for success and failure cases, verify fields are set correctly.

  3. **`test_index_dedup_human_index_built_once`**: Mock `create_indexes` and call `run_pipeline` with 2 plasmid files (creating 2 combinations). Verify that `create_indexes` is called with the human_fasta argument exactly ONCE (the upfront call), not twice. Mock all other pipeline steps (align_reads, compare_alignments, generate_report, etc.) to be no-ops. Use `tmp_path` to create minimal dummy input files.

  4. **`test_index_dedup_plasmid_indexes_still_per_combination`**: Same setup as above but verify `create_indexes` is still called for each plasmid FASTA (no dedup for plasmid indexes, per CONTEXT decision).

  5. **`test_batch_resilience_continues_on_failure`**: Mock one of the pipeline steps (e.g., `compare_alignments`) to raise an exception on the first combination but succeed on the second. Verify that `run_pipeline` does NOT raise, and that both combinations were attempted (check that `generate_report` or another later step was called for the second combination).

  6. **`test_batch_resilience_all_fail_raises`**: Mock a pipeline step to raise for ALL combinations. Verify that `run_pipeline` raises RuntimeError with a summary of failures.

  7. **`test_per_combination_timing_logged`**: Mock pipeline steps, run with 1 combination, capture log output, verify an INFO log line with timing (matches pattern like "x Plasmid: NN.Ns").

  Use `pytest.mark.unit` marker. Use `unittest.mock.patch` extensively. Use `tmp_path` for file fixtures. Create minimal dummy files (empty FASTA, empty plasmid GenBank) where needed for quality_control to pass, or mock quality_control.
  </action>
  <verify>
  - `pytest tests/test_run_pipeline.py -v -k "test_index_dedup or test_batch_resilience or test_combination_result or test_per_combination"` — all new tests pass
  - `make test-fast` passes (all unit tests)
  - `make lint && make typecheck` passes
  </verify>
  <done>
  - 7 new tests covering PipelinePlan.built_indexes, CombinationResult, index dedup for human (once) and plasmid (per-combo), batch resilience continue-on-failure, all-fail raises, and timing logging
  - All tests pass
  - No regressions in existing run_pipeline tests
  </done>
</task>

</tasks>

<verification>
1. `make ci-check` passes (lint + format + typecheck + test)
2. `python scripts/regression_test.py` passes (if test data available)
3. `grep -n "built_indexes" plasmicheck/scripts/run_pipeline.py` shows index tracking
4. `grep -n "CombinationResult" plasmicheck/scripts/run_pipeline.py` shows batch result tracking
5. `grep -n "Skipping index" plasmicheck/scripts/run_pipeline.py` shows dedup log message
6. `grep -n "FAILED after" plasmicheck/scripts/run_pipeline.py` shows batch resilience error logging
</verification>

<success_criteria>
- Human reference indexing hoisted out of combination loop (ARCH-01)
- PipelinePlan tracks built indexes, skips redundant operations (ARCH-02)
- Pipeline continues on combination failure, logs errors, reports summary
- Per-combination timing logged at INFO level
- 7+ new tests for index dedup and batch resilience
</success_criteria>

<output>
After completion, create `.planning/phases/07-comparison-cleanup/07-02-SUMMARY.md`
</output>
