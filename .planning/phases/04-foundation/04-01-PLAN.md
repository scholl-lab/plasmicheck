---
phase: 04-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/regression_test.py
  - .gitignore
autonomous: true

must_haves:
  truths:
    - "Running `python scripts/regression_test.py --generate` creates a baseline from the current pipeline output"
    - "Running `python scripts/regression_test.py` compares current pipeline output against cached baseline"
    - "Regression test passes when contamination ratios, read assignment counts, and verdicts match baseline within tolerance"
    - "Regression test fails with a clear message when verdicts differ or ratios diverge beyond 0.001"
    - "Baseline cache is stored atomically (no corruption on crash)"
  artifacts:
    - path: "scripts/regression_test.py"
      provides: "Standalone regression testing script"
      min_lines: 150
    - path: "scripts/.regression_cache/"
      provides: "Local baseline cache directory (gitignored)"
  key_links:
    - from: "scripts/regression_test.py"
      to: "plasmicheck.scripts.run_pipeline.run_pipeline"
      via: "Python import, calling run_pipeline() with synthetic test data"
      pattern: "from plasmicheck\\.scripts\\.run_pipeline import run_pipeline"
    - from: "scripts/regression_test.py"
      to: "tests/data/synthetic/"
      via: "Path references to human_ref.fasta, plasmid.gb, contaminated FASTQs"
      pattern: "tests/data/synthetic"
    - from: "scripts/regression_test.py"
      to: "scripts/.regression_cache/baseline.json"
      via: "Atomic JSON write (tempfile + os.replace) and load"
      pattern: "os\\.replace"
---

<objective>
Create a standalone regression test script that validates pipeline outputs have not changed after code modifications.

Purpose: Phases 5-7 will modify core pipeline code (report generation, alignment, comparison). This script ensures those optimizations preserve correctness by comparing contamination ratios, read assignment counts, and verdicts against a v0.31.0 baseline.

Output: `scripts/regression_test.py` -- a self-contained CLI script that generates baselines, compares results, and reports pass/fail.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-foundation/04-CONTEXT.md
@.planning/phases/04-foundation/04-RESEARCH.md

Key source files:
@plasmicheck/scripts/run_pipeline.py (run_pipeline function signature and output structure)
@tests/test_integration.py (existing integration test pattern for synthetic data)
@tests/conftest.py (synthetic_data_dir fixture path)
@tests/data/synthetic/expected/contaminated.verdict.txt (expected verdict)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create regression test script</name>
  <files>scripts/regression_test.py</files>
  <action>
Create `scripts/regression_test.py` as a standalone CLI script (not a pytest test). Use argparse with two modes:

**CLI interface:**
- `python scripts/regression_test.py --generate` -- Run pipeline on synthetic data, save results as baseline
- `python scripts/regression_test.py` -- Run pipeline on synthetic data, compare against cached baseline
- `python scripts/regression_test.py --baseline-dir PATH` -- Override cache directory (default: `scripts/.regression_cache/`)

**Baseline generation (`--generate`):**
1. Import `run_pipeline` from `plasmicheck.scripts.run_pipeline`
2. Run pipeline with synthetic contaminated data (same args as `test_integration.py:TestPipelineContaminated`):
   - `human_fasta`: `tests/data/synthetic/human_ref.fasta`
   - `plasmid_files`: `tests/data/synthetic/plasmid.gb`
   - `sequencing_files_r1`: `tests/data/synthetic/contaminated_R1.fastq`
   - `sequencing_files_r2`: `tests/data/synthetic/contaminated_R2.fastq`
   - `output_folder`: temp directory (use `tempfile.TemporaryDirectory`)
   - `overwrite=True`, `threshold=0.8`
3. Also run with not_contaminated data (same pattern, using `not_contaminated_R1/R2.fastq`)
4. After each run, glob for `*.summary.tsv` and `*.reads_assignment.tsv` in the output directory
5. Read TSV contents as raw text, store in a dict keyed by scenario name ("contaminated", "not_contaminated")
6. Store version from `plasmicheck.version.__version__` in baseline metadata
7. Save baseline dict as JSON using atomic write pattern:
   - Write to `tempfile.mkstemp()` in cache dir
   - `json.dump()` with `indent=2`
   - `os.replace()` temp file to `baseline.json` (POSIX atomic rename)
8. Print success message with baseline path and version

**Comparison mode (default, no flags):**
1. Load baseline from `scripts/.regression_cache/baseline.json`
   - If missing, print error "No baseline found. Run with --generate first." and exit(1)
2. Check stored version matches current version -- if mismatch, print WARNING (not error) that baseline was generated with different version
3. Run pipeline with same args as generation (both contaminated and not_contaminated scenarios)
4. For each scenario, compare:
   - **summary.tsv**: Parse with `pandas.read_csv(sep='\t', dtype=str)`. For each row:
     - If Category is "Verdict": exact string match (case-insensitive)
     - If Category is "Plasmid", "Human", "Tied": exact integer match
     - If Category is "Ratio" or "CoverageOutsideINSERT": float comparison with `abs(baseline - current) <= 0.001`
     - If Category is "MismatchesNearINSERT": string match (it's a dict repr)
   - **reads_assignment.tsv**: Parse with pandas. Compare:
     - Row count must match exactly
     - "AssignedTo" column: exact match (same reads assigned to same category)
     - "PlasmidScore" and "HumanScore" columns: float comparison within tolerance 0.001
5. Print per-scenario results: PASS or FAIL with details on which fields differ
6. Exit 0 if all pass, exit 1 if any fail

**Important details:**
- Use `pathlib.Path` for all paths, resolve relative to script location using `Path(__file__).resolve().parent`
- Resolve synthetic data paths relative to repo root: `Path(__file__).resolve().parent.parent / "tests" / "data" / "synthetic"`
- Add a warm-up note in the `--help` text: "First run may be slower due to index generation"
- Suppress pipeline logging during runs by setting log level to WARNING
- Handle the case where pipeline output structure varies (glob for TSV files, don't hardcode subdirectory names)
- Add `if __name__ == "__main__":` guard
- Include proper type hints for all functions (mypy strict compatible)
- Follow ruff formatting conventions (match project style)
  </action>
  <verify>
Run `python -c "import ast; ast.parse(open('scripts/regression_test.py').read())"` to verify syntax.
Run `python -m ruff check scripts/regression_test.py` to verify lint.
Run `python -m mypy scripts/regression_test.py --strict` to verify types (may need to ignore some imports).
  </verify>
  <done>
`scripts/regression_test.py` exists with both `--generate` and comparison modes. Script parses cleanly, passes ruff lint, and has complete type annotations.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add regression cache to gitignore and verify end-to-end</name>
  <files>.gitignore</files>
  <action>
1. Add the following entry to `.gitignore` (under the existing "# claude files and folders" section or create a new "# Regression/benchmark cache" section at the end):
   ```
   # Regression and benchmark cache
   scripts/.regression_cache/
   BENCHMARK.md
   ```

2. Create the cache directory: `mkdir -p scripts/.regression_cache/`

3. Run the regression test end-to-end to verify it works:
   - First run `python scripts/regression_test.py --generate` to create baseline
   - Then run `python scripts/regression_test.py` to compare against baseline
   - Both should complete without errors (exit code 0)

4. If either step fails, debug and fix the script (Task 1). Common issues:
   - Missing minimap2/samtools (skip with informative error)
   - Path resolution issues (ensure paths work from repo root)
   - Pipeline output directory structure differences

Note: This task requires minimap2 and samtools on PATH. If unavailable, verify script syntax and structure only, and add a clear skip message.
  </action>
  <verify>
`grep -q "regression_cache" .gitignore` confirms gitignore entry.
If minimap2/samtools available: `python scripts/regression_test.py --generate && python scripts/regression_test.py` exits 0.
If tools unavailable: script prints informative error about missing tools.
  </verify>
  <done>
Gitignore updated. If external tools available: baseline generated and comparison passes. If tools unavailable: script gives clear error message about requirements.
  </done>
</task>

</tasks>

<verification>
1. `scripts/regression_test.py` exists and is syntactically valid Python
2. Script has `--generate` and `--baseline-dir` CLI flags
3. Script uses atomic write pattern (tempfile + os.replace) for baseline caching
4. Script compares verdicts exactly and ratios with tolerance
5. `.gitignore` includes `scripts/.regression_cache/`
6. If tools available: end-to-end generate + compare cycle works
</verification>

<success_criteria>
- Regression test script can generate baseline from v0.31.0 synthetic pipeline output
- Regression test script can compare current output against baseline with tolerance
- Verdicts must match exactly; ratios must match within 0.001
- Read assignment counts and categories must match exactly
- Script exits 0 on pass, 1 on fail, with clear messages
- TEST-01 requirement satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/04-foundation/04-01-SUMMARY.md`
</output>
