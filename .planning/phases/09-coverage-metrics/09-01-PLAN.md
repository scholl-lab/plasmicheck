---
phase: 09-coverage-metrics
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - plasmicheck/scripts/coverage_metrics.py
  - plasmicheck/scripts/compare_alignments.py
  - plasmicheck/config.json
  - tests/test_coverage_metrics.py
  - tests/conftest.py
autonomous: true

must_haves:
  truths:
    - "Running the pipeline produces summary.tsv with MeanDepthInsert, MeanDepthBackbone, MedianDepthInsert, MedianDepthBackbone rows"
    - "summary.tsv contains BreadthInsert, BreadthBackbone, and BreadthBackbone_5x rows with fraction values 0.00-1.00"
    - "summary.tsv contains CoverageCV_Insert and CoverageCV_Backbone rows"
    - "Existing summary.tsv rows (Plasmid, Human, Tied, Backbone_Only, Ambiguous, Verdict, Ratio, CoverageOutsideINSERT, MismatchesNearINSERT) are unchanged"
    - "When cDNA_positions.txt is missing, coverage metrics are computed for whole plasmid with fallback labels"
    - "When no reads align, all coverage metrics are 0.00"
  artifacts:
    - path: "plasmicheck/scripts/coverage_metrics.py"
      provides: "Coverage computation engine with per-region metrics"
      exports: ["compute_region_coverage_metrics"]
    - path: "plasmicheck/config.json"
      provides: "breadth_thresholds configuration"
      contains: "breadth_thresholds"
    - path: "tests/test_coverage_metrics.py"
      provides: "Unit tests for coverage metric computation"
      min_lines: 100
  key_links:
    - from: "plasmicheck/scripts/compare_alignments.py"
      to: "plasmicheck/scripts/coverage_metrics.py"
      via: "import and call compute_region_coverage_metrics()"
      pattern: "from .coverage_metrics import"
    - from: "plasmicheck/scripts/compare_alignments.py"
      to: "summary.tsv"
      via: "summary_file.write() calls for new coverage rows"
      pattern: "MeanDepthInsert|BreadthBackbone|CoverageCV"
    - from: "plasmicheck/scripts/coverage_metrics.py"
      to: "pysam.AlignmentFile.count_coverage()"
      via: "per-base depth extraction"
      pattern: "count_coverage"
---

<objective>
Implement per-region coverage metrics computation (depth, breadth, uniformity) and write results to summary.tsv.

Purpose: COV-01 through COV-05 require quantitative coverage metrics computed from actual per-base depth via pysam, written as new rows in summary.tsv while preserving backward compatibility with existing rows.

Output: New coverage_metrics.py module with compute_region_coverage_metrics(), updated compare_alignments.py that calls it and writes coverage rows to summary.tsv, updated config.json with breadth_thresholds, and comprehensive unit tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-coverage-metrics/09-CONTEXT.md
@.planning/phases/09-coverage-metrics/09-RESEARCH.md
@.planning/phases/08-insert-region-aware-filtering/08-01-SUMMARY.md
@plasmicheck/scripts/compare_alignments.py
@plasmicheck/config.json
@tests/conftest.py
@tests/test_compare_alignments.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Coverage metrics module + config + pipeline wiring</name>
  <files>
    plasmicheck/scripts/coverage_metrics.py
    plasmicheck/scripts/compare_alignments.py
    plasmicheck/config.json
  </files>
  <action>
    Create a new module `plasmicheck/scripts/coverage_metrics.py` containing the coverage computation engine:

    1. **`get_depth_array(bam_path, contig, start, end) -> np.ndarray`**
       - Use pysam.AlignmentFile.count_coverage() with quality_threshold=0 and read_callback="all"
       - Sum the 4 returned arrays (A, C, G, T) to get total depth per position
       - Return numpy array of per-base depths
       - Handle empty regions (return np.array([]) if start >= end)

    2. **`compute_coverage_stats(depth_array, breadth_thresholds) -> dict[str, float]`**
       - Compute mean_depth (float), median_depth (float) from numpy
       - Compute breadth at each threshold: fraction of bases with depth >= threshold
       - Compute cv (coefficient of variation): std(ddof=1) / mean, with explicit zero-check (return 0.0 if mean is 0 or array is empty)
       - Return dict with keys: "mean_depth", "median_depth", "breadth_Nx" for each threshold N, "cv"
       - All values as Python floats (not numpy scalars)
       - If depth_array is empty, return all 0.0

    3. **`compute_region_coverage_metrics(plasmid_bam, insert_region, breadth_thresholds) -> tuple[dict[str, dict[str, float]], bool]`**
       - Open BAM with pysam to get contig name (get_reference_name(0)) and plasmid_length (lengths[0])
       - If insert_region is None (fallback): compute metrics for whole plasmid, return as "insert" key with empty "backbone" (all 0.0), and bool fallback=True
       - If insert_region is provided: compute insert depth array using [start, end+1) (inclusive-to-half-open conversion), compute backbone as concatenation of [0, start) and [end+1, plasmid_length)
       - Return ({"insert": stats_dict, "backbone": stats_dict}, fallback_bool)
       - Use numpy.concatenate for backbone arrays, handle case where backbone has no bases before or after insert

    Important implementation details:
    - Import numpy as np at module top
    - Import pysam at module top (follows existing pattern in compare_alignments.py)
    - Add type annotations throughout (mypy strict compatibility)
    - Use `from __future__ import annotations` at top
    - Load breadth_thresholds from config: `_cfg.get("breadth_thresholds", [5])` with default [5]
    - Document the off-by-one convention in docstrings: insert_region uses inclusive boundaries, pysam uses half-open

    Then update `plasmicheck/config.json`:
    - Add `"breadth_thresholds": [5]` as a top-level config key (after "score_margin")

    Then update `plasmicheck/scripts/compare_alignments.py`:
    - Import: `from .coverage_metrics import compute_region_coverage_metrics`
    - Load config: `BREADTH_THRESHOLDS: list[int] = _cfg.get("breadth_thresholds", [5])`
    - In `compare_alignments()` function, after computing coverage_outside_insert and mismatches_near_insert (around line 350-355), add a call to compute_region_coverage_metrics(plasmid_bam, insert_region, BREADTH_THRESHOLDS)
    - Store the returned (coverage_metrics, coverage_fallback) values
    - When insert_region is None, still call compute_region_coverage_metrics with insert_region=None (it handles the fallback internally)
    - In the summary.tsv writing block (around line 406-413), AFTER the existing MismatchesNearINSERT line, append new coverage rows using the coverage_metrics dict
    - Row names in CamelCase: MeanDepthInsert, MedianDepthInsert, BreadthInsert, CoverageCV_Insert, MeanDepthBackbone, MedianDepthBackbone, BreadthBackbone, BreadthBackbone_5x, CoverageCV_Backbone
    - For configurable breadth thresholds: write BreadthInsert (1x), BreadthBackbone (1x) always, then BreadthInsert_Nx and BreadthBackbone_Nx for each threshold N in breadth_thresholds
    - Format all values with :.2f (2 decimal places per CONTEXT decision)
    - After the last coverage metric row (CoverageCV_Backbone), write a `CoverageFallback\t{True|False}` row to summary.tsv (value is string "True" or "False") so downstream report generation can detect fallback mode
    - If coverage_fallback is True, log a warning about whole-plasmid fallback
    - DO NOT change any existing summary.tsv rows — new rows are appended after existing ones
  </action>
  <verify>
    Run `make lint && make typecheck` to confirm no lint or type errors.
    Run `python -c "from plasmicheck.scripts.coverage_metrics import compute_region_coverage_metrics; print('import OK')"` to confirm module is importable.
  </verify>
  <done>
    coverage_metrics.py exists with compute_region_coverage_metrics(), config.json has breadth_thresholds, compare_alignments.py calls coverage computation and writes new rows to summary.tsv after existing rows. All code passes lint and typecheck.
  </done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for coverage metrics</name>
  <files>
    tests/test_coverage_metrics.py
    tests/conftest.py
  </files>
  <action>
    Create `tests/test_coverage_metrics.py` with comprehensive unit tests:

    **TestGetDepthArray (3-4 tests, using mock pysam):**
    - Test that count_coverage is called with quality_threshold=0 and read_callback="all"
    - Test that 4 arrays (A,C,G,T) are summed correctly to produce total depth
    - Test empty region (start >= end) returns empty array

    **TestComputeCoverageStats (6-8 tests, pure numpy, no mocking needed):**
    - Test mean_depth and median_depth for known arrays (e.g., np.array([10, 20, 30]) -> mean=20.0, median=20.0)
    - Test breadth at 1x threshold: np.array([0, 5, 10, 0, 3]) -> 3/5 = 0.6
    - Test breadth at 5x threshold: np.array([0, 5, 10, 0, 3]) -> 2/5 = 0.4
    - Test CV computation: known array with calculable std/mean
    - Test all-zero array: mean=0, breadth=0, cv=0
    - Test empty array: all metrics return 0.0
    - Test single-element array: cv=0 (no variance)
    - Test multiple breadth thresholds: [1, 5, 10] each produces correct breadth key

    **TestComputeRegionCoverageMetrics (5-6 tests, mock pysam.AlignmentFile):**
    - Test with insert_region provided: metrics computed separately for insert and backbone
    - Test with insert_region=None (fallback): whole plasmid as "insert", backbone all 0.0, fallback=True
    - Test insert at start of plasmid (insert_region[0] == 0): backbone only after insert
    - Test insert at end of plasmid: backbone only before insert
    - Test off-by-one: insert_region uses inclusive boundaries, verify end+1 passed to count_coverage
    - Test BAM with zero mapped reads: all metrics 0.0

    **TestSummaryTsvCoverageRows (3-4 tests, mock-based):**
    - Test that compare_alignments writes coverage rows after MismatchesNearINSERT
    - Test that existing rows (Plasmid, Human, Tied, etc.) are unchanged
    - Test row names match CamelCase convention
    - Test fallback behavior when insert_region is None

    Use pytest.mark.unit decorator on all tests. Use unittest.mock.patch for pysam.AlignmentFile.
    Follow existing test patterns in tests/test_compare_alignments.py for mock setup.

    Update `tests/conftest.py`:
    - Add a `sample_summary_df_with_coverage` fixture that includes the new coverage rows in the Category/Count columns (MeanDepthInsert, MedianDepthInsert, BreadthInsert, etc.) with sample values. This fixture will be used by Plan 02's report tests.
  </action>
  <verify>
    Run `make test-fast` — all existing 195 tests pass plus new coverage tests pass.
    Run `make lint && make typecheck` — no errors.
  </verify>
  <done>
    At least 15 new unit tests in test_coverage_metrics.py covering depth extraction, statistics computation, region splitting, and summary.tsv integration. All tests pass. conftest.py has sample_summary_df_with_coverage fixture.
  </done>
</task>

</tasks>

<verification>
1. `make ci-check` passes (lint + format + typecheck + all tests)
2. Coverage metrics module is importable: `python -c "from plasmicheck.scripts.coverage_metrics import compute_region_coverage_metrics"`
3. Config has breadth_thresholds: `python -c "from plasmicheck.config import get_config; print(get_config()['breadth_thresholds'])"`
4. New tests cover edge cases: empty arrays, zero depth, missing insert region, off-by-one boundaries
</verification>

<success_criteria>
- COV-01: Per-region mean and median depth computed for insert and backbone regions (via compute_coverage_stats)
- COV-02: Breadth of coverage (fraction >=1 read) computed per region (breadth_1x in stats)
- COV-03: Breadth at 5x threshold computed per region (breadth_5x in stats, configurable via breadth_thresholds)
- COV-04: Coverage uniformity (CV) computed for insert and backbone regions (cv in stats)
- COV-05: All new metrics written as additional rows in summary.tsv after existing rows (backward compatible)
- All 195+ existing tests still pass
- 15+ new tests covering coverage metric computation
</success_criteria>

<output>
After completion, create `.planning/phases/09-coverage-metrics/09-01-SUMMARY.md`
</output>
